{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HromovAndrey/II_Homework_mood_6_part_3/blob/main/%D0%94%D0%97_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання\n",
        "\n",
        "* Завантажте дані\n",
        "* Розділіть дані на тренувальні та тестові\n",
        "* У `MyTokenizer` добавте обробку тексту за допомогою `nltk`, застосуйте **стематизацію**\n",
        "* Застосуйте `TfidfVectorizer`\n",
        "* Застосуйте `TruncatedSVD`\n",
        "* Натренуйте модель [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) з параметром `kernel=\"linear\"`, якщо вистачить пам'яті можна спробувати `kernel=\"rbf\"`\n",
        "* Виведіть результати"
      ],
      "metadata": {
        "id": "5QELje_64yp4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дані про телеграм"
      ],
      "metadata": {
        "id": "c0s4j60x4tLg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZ3aCzvW39j7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/HalyshAnton/IT-Step-Pyton-AI/main/module6/data/telegram_spam.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Загрузка данных\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/HalyshAnton/IT-Step-Pyton-AI/main/module6/data/telegram_spam.csv\")\n",
        "\n",
        "# Просмотр первых строк данных\n",
        "print(df.head())\n",
        "\n",
        "# Определение признаков и меток\n",
        "X = df['message']  # Используем сообщения как признаки\n",
        "y = df['label']  # Метки спама или не спама\n",
        "\n",
        "# Разделение данных на обучающие и тестовые наборы\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
        "\n",
        "# Загрузка ресурсов NLTK\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Кастомный токенайзер с использованием стемматизации\n",
        "class MyTokenizer:\n",
        "    def __init__(self):\n",
        "        self.stemmer = PorterStemmer()\n",
        "\n",
        "    def __call__(self, text):\n",
        "        tokens = word_tokenize(text.lower())  # Токенизация и преобразование в нижний регистр\n",
        "        stemmed_tokens = [self.stemmer.stem(token) for token in tokens]  # Стемматизация\n",
        "        return stemmed_tokens\n",
        "\n",
        "# Преобразование текста в числовой формат с использованием TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(tokenizer=MyTokenizer(), stop_words='english')\n",
        "\n",
        "# Преобразование обучающих и тестовых данных в TF-IDF векторы\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Применение TruncatedSVD для снижения размерности\n",
        "pca = TruncatedSVD(n_components=min(300, X_train_tfidf.shape[1]))  # Снижение размерности до 300 компонент или меньше\n",
        "\n",
        "# Преобразование обучающих и тестовых данных\n",
        "X_train_reduced = pca.fit_transform(X_train_tfidf)\n",
        "X_test_reduced = pca.transform(X_test_tfidf)\n",
        "\n",
        "print(\"Размерность после SVD:\", X_train_reduced.shape, X_test_reduced.shape)\n",
        "\n",
        "# Обучение модели SVC с kernel=\"linear\"\n",
        "svc_linear = SVC(kernel=\"linear\", class_weight=\"balanced\")\n",
        "svc_linear.fit(X_train_reduced, y_train)\n",
        "\n",
        "# Предсказание и оценка модели SVC с kernel=\"linear\"\n",
        "y_pred_linear = svc_linear.predict(X_test_reduced)\n",
        "\n",
        "# Выводим отчет о классификации\n",
        "print(\"Результаты для SVC с kernel='linear':\")\n",
        "print(classification_report(y_test, y_pred_linear))\n",
        "\n",
        "# Построение матрицы ошибок\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_linear, display_labels=svc_linear.classes_)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Confusion Matrix for SVC with kernel='linear'\")\n",
        "plt.show()\n",
        "\n",
        "# Обучение модели SVC с kernel=\"rbf\", если хватает памяти\n",
        "try:\n",
        "    svc_rbf = SVC(kernel=\"rbf\", class_weight=\"balanced\")\n",
        "    svc_rbf.fit(X_train_reduced, y_train)\n",
        "\n",
        "    # Предсказание и оценка модели SVC с kernel=\"rbf\"\n",
        "    y_pred_rbf = svc_rbf.predict(X_test_reduced)\n",
        "\n",
        "    # Выводим отчет о классификации\n",
        "    print(\"Результаты для SVC с kernel='rbf':\")\n",
        "    print(classification_report(y_test, y_pred_rbf))\n",
        "\n",
        "    # Построение матрицы ошибок\n",
        "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred_rbf, display_labels=svc_rbf.classes_)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(\"Confusion Matrix for SVC with kernel='rbf'\")\n",
        "    plt.show()\n",
        "\n",
        "except MemoryError:\n",
        "    print(\"Недостаточно памяти для выполнения модели SVC с kernel='rbf'.\")\n"
      ],
      "metadata": {
        "id": "vRhWPRoA4ly4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "e5dee9e4-95eb-48cd-a491-b4eb1ef960b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  text_type                                               text\n",
            "0      spam  naturally irresistible your corporate identity...\n",
            "1      spam  the stock trading gunslinger fanny is merrill ...\n",
            "2      spam  unbelievable new homes made easy im wanting to...\n",
            "3      spam  4 color printing special request additional in...\n",
            "4      spam  do not have money get software cds from here s...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'message'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'message'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-702983315a2d>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Определение признаков и меток\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Используем сообщения как признаки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Метки спама или не спама\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m             ):\n\u001b[1;32m   3797\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'message'"
          ]
        }
      ]
    }
  ]
}